{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d626160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import scienceplots\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57078960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import scienceplots\n",
    "\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "plt.style.use(['science', 'grid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df8aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, loss_fn, clf, theta=None):\n",
    "        self.loss_fn = loss_fn\n",
    "        self.clf = clf\n",
    "        if not theta is None:\n",
    "            self.theta = theta\n",
    "        else:\n",
    "            self.theta = torch.ones(X.shape[1])\n",
    "    \n",
    "    def decision_function(self, X):\n",
    "        return self.clf(X, self.theta).flatten()\n",
    "    \n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        if sample_weight is None:\n",
    "            sample_weight = torch.ones(X.shape[0], self.theta.shape[0])\n",
    "        y_hats = self.decision_function(X)\n",
    "        return self.loss_fn(y, y_hats, sample_weight=sample_weight)\n",
    "    \n",
    "    def fit(self, X, y, sample_weight, max_iters=1_000, lr=0.0001, quiet=True, round_lr=False): # n x m\n",
    "        theta = torch.clone(self.theta)\n",
    "        theta.requires_grad_(True)\n",
    "        lrs = np.exp(np.linspace(np.log(0.1), np.log(lr), max_iters))\n",
    "        for i in (pbar := tqdm(range(max_iters), position=0, leave=True, disable=quiet)):\n",
    "            theta = theta.detach()\n",
    "            theta.requires_grad_(True)\n",
    "            optimizer = torch.optim.Adam([theta], lr=lrs[i])\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_hats = self.clf(X, theta)\n",
    "            loss = self.loss_fn(y, y_hats, sample_weight=sample_weight)\n",
    "            \n",
    "            pbar.set_description(f'Loss: {loss:.2f}')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if round_lr:\n",
    "            theta = torch.round(theta, decimals=int(1 - np.log10(lr)))\n",
    "        self.theta = theta.detach()\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e86420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data & fix\n",
    "X = torch.tensor([[1, 1, 1], [1, 1, 1], [1, -1, 1], [-1, 1, 1], [-1, -1, 1]], dtype=torch.float)\n",
    "y = torch.tensor([1, 1, -1, -1, -1], dtype=torch.float)\n",
    "theta_0_np = np.array([[1, 0, 0], [0, 1, 0]], dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a6f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pos = np.where(y == 1)[0]\n",
    "idx_neg = np.where(y == -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd734e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doublecheck fit\n",
    "svm = sklearn.svm.SVC(kernel='rbf')\n",
    "svm.fit(X, y=y)\n",
    "svm.score(X, y=y), svm.score(X[y==-1.0], y[y==-1.0]), svm.score(X[y==1.0], y[y==1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93abb739",
   "metadata": {},
   "source": [
    "# All At Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583cd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization \n",
    "\n",
    "p = 0.5\n",
    "m = theta_0_np.shape[0]\n",
    "n, d = X.shape\n",
    "clf = new_clf\n",
    "loss_fn = hinge_loss\n",
    "epochs = 10\n",
    "EXP_NAME = f'n={n}_m={m}_p={p}_e={epochs}_linclf_hingeloss'\n",
    "\n",
    "models = [Model(loss_fn=loss_fn, clf=clf, theta=torch.tensor(theta_0_np[j], dtype=torch.float)) for j in range(m)]\n",
    "# Collect scores\n",
    "y_hats = []\n",
    "for j in range(m):\n",
    "    y_hats.append(models[j].decision_function(X))\n",
    "y_hats = torch.stack(y_hats).T\n",
    "M = torch.zeros_like(y_hats)\n",
    "\n",
    "# Setup End-Of-Run Stats\n",
    "\n",
    "y_hats_eor = []\n",
    "alphas_eor = []\n",
    "Ms_eor = []\n",
    "models_eor = []\n",
    "\n",
    "# Iterable\n",
    "\n",
    "for e in range(epochs):\n",
    "    y_hats_eor.append(y_hats)\n",
    "    # Optimize alpha\n",
    "    alpha = opt_alpha(y_hats, quiet=False, round_lr=True)\n",
    "    alphas_eor.append(alpha)\n",
    "    # Update memory\n",
    "    M = cache_memory(alpha=alpha, mem=M, p=p)\n",
    "    Ms_eor.append(M)\n",
    "    # Train new models\n",
    "    models = [Model(loss_fn=loss_fn, clf=linear_clf).fit(X, y=y, sample_weight=M.T[j], max_iters=2_000) for j in range(m)]\n",
    "    models = [Model(loss_fn=loss_fn, clf=maxlin_clf, theta=models[j].theta).fit(X, y=y, sample_weight=M.T[j], max_iters=2_000) for j in range(m)]\n",
    "    models_eor.append(models)\n",
    "    # Collect new scores\n",
    "    y_hats = []\n",
    "    for j in range(m):\n",
    "        y_hats.append(models[j].decision_function(X))\n",
    "    y_hats = torch.stack(y_hats).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e92ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First graph the differences, then the alphas for model 1, then the alphas for model 2\n",
    "\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "fig, ax = plt.subplots(1, 1+m, figsize=(17,3))\n",
    "\n",
    "NUM_LINES = 6\n",
    "prevs = []\n",
    "ax[0].set_title(r'Service Loss $\\sum_{i=1}^n \\sum_{j=1}^m A_{i,j}^t \\ell(h_j^t, x_i, y_i)$')\n",
    "for j in range(m):\n",
    "    M = Ms_eor[j]\n",
    "    y_hats = [models_eor[e][j].score(X, y, sample_weight=alphas_eor[e+1].T[j]) for e in range(epochs-1)]\n",
    "    style = '--' if np.any([np.allclose(p_yhts, y_hats) for p_yhts in prevs]) else '-'\n",
    "    ax[0].plot(range(epochs-1), y_hats, style, marker=NUM_LINES, label=f'Model j={j}')\n",
    "    prevs.append(y_hats)\n",
    "    NUM_LINES += 1\n",
    "ax[0].set_xticks(range(0, epochs-1, 2))\n",
    "ax[0].set_xlabel(r'Epochs (t)')\n",
    "# ax[0].legend()\n",
    "\n",
    "prev_plots = 1\n",
    "\n",
    "# Next plot alphas\n",
    "for j in range(m):\n",
    "    NUM_LINES = 6\n",
    "    ax[prev_plots+j].set_title(r'Usages $A_{i,' + repr(str(j))[1:-1] + r'}$')\n",
    "    prevs = []\n",
    "    for i in range(n):\n",
    "        alphas_ij = [alphas_eor[e][i,j] for e in range(epochs)]\n",
    "        style = '--' if np.any([np.allclose(p_alphas, alphas_ij) for p_alphas in prevs]) else '-'\n",
    "        ax[prev_plots+j].plot(range(epochs), alphas_ij, style, marker=NUM_LINES, label=r'$x_i = $' + repr(f'{X[i,:-1].tolist()}')[1:-1])\n",
    "        NUM_LINES += 1\n",
    "        prevs.append(alphas_ij)\n",
    "    max_val = int(np.ceil(np.max(prevs)))\n",
    "    ax[prev_plots+j].set_xticks([0] + list(range(1, epochs, 2)))\n",
    "    ax[prev_plots+j].set_yticks(np.linspace(0, max_val, 1 + max_val * 2))\n",
    "    ax[prev_plots+j].set_xlabel(r'Epochs (t)')\n",
    "ax[-1].legend(loc=7)\n",
    "\n",
    "fig.tight_layout(pad=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04177e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
